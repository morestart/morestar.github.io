{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 自定义层"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "tf官方推荐使用`tf.keras`作为高级抽象API来构建神经网络.这意味着,大多数tf api均可执行在动态图中."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "source": [
    "## 网络层:一些有用的公共操作\n",
    "许多机器学习模型都可以表示为相对简单的层的组合和堆叠，而TensorFlow既提供了许多公共层的集合，也为您提供了一种简单的方法，可以从头开始编写自己的特定于应用程序的层，也可以是现有层的组合。\n",
    "\n",
    "在`tf.keras`中包含了全部的keras API,在编译你的模型的时候keras层是非常有用的.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 实现自定义层\n",
    "\n",
    "实现自定义层最好的方式就是继承`tf.keras.Layer`类并实现以下方法:\n",
    "\n",
    "1. `__inti__`这里可以做一些与输入无关的初始化操作\n",
    "\n",
    "2. `build`这里是你知道输入张量的维度而且你可以初始化的其他部分\n",
    "\n",
    "3. `call`前向计算\n",
    "\n",
    "请注意，您不必等到调用`build`来创建变量，您也可以在`__init__`中创建它们。但是，在`build`中创建它们的好处是，它可以根据层将要操作的输入的形状进行后期变量创建。另一方面，在`__init__`中创建变量意味着需要显式指定创建变量所需的形状。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]),self.num_outputs])\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.matmul(input, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "source": [
    "如果尽可能使用标准层，则总体代码更易于阅读和维护，因为其他读者将熟悉标准层的行为。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 模型:多层组合\n",
    "\n",
    "机器学习模型中许多有趣的层都是通过组合现有层来实现的。例如, resnet的每一个残差块都是通过卷积,皮归一化和连接实现的,层可以嵌套在其他层中。\n",
    "\n",
    "当你需要`Model.fit` `Model.evaluate` `Model.save`方法时,你可以通过继承`keras.Model`类\n",
    "\n",
    "另一项功能由`keras.Model`（而不是`keras.layers.Layer`)除了跟踪变量外`keras.Model`还可以跟踪其内部层，使其更易于检查。\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 3, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x2afeb3e5708>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2afeb5f0888>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2afeb21a548>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2afeb21f9c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2afeb221a08>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2afeb226788>]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"resnet_identity_block\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            multiple                  4         \n_________________________________________________________________\nbatch_normalization (BatchNo multiple                  4         \n_________________________________________________________________\nconv2d_2 (Conv2D)            multiple                  4         \n_________________________________________________________________\nbatch_normalization_1 (Batch multiple                  8         \n_________________________________________________________________\nconv2d_3 (Conv2D)            multiple                  9         \n_________________________________________________________________\nbatch_normalization_2 (Batch multiple                  12        \n=================================================================\nTotal params: 41\nTrainable params: 29\nNon-trainable params: 12\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "source": [
    "然而,大多数情况下,模型可以简单的使用`tf.keras.Sequential`来进行堆栈组合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}